{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering agent that is an expert knowledge worker\n",
    "### To be used by employees of Insurellm, an Insurance Tech company\n",
    "### The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy.\n",
    "\n",
    "This first implementation will use a simple, brute-force type of RAG..\n",
    "\n",
    "### Sidenote: Business applications of this week's projects\n",
    "\n",
    "RAG is perhaps the most immediately applicable technique of anything that we cover in the course! In fact, there are commercial products that do precisely what we build this week: nuanced querying across large databases of information, such as company contracts or product specs. RAG gives you a quick-to-market, low cost mechanism for adapting an LLM to your business area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"qwen/qwen3-next-80b-a3b-thinking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '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')\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0652c2-3d76-40c7-8313-9dc1895155a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "FILE NAME: bio\n",
      "----------------------------\n",
      "# Professional Bio\n",
      "\n",
      "Ayush Tyagi is a dedicated Computer Science Engineering student at JIMS, Greater Noida (IP University), on track to graduate in 2025. With a strong foundation built during his PCM schooling at Vivekanand School, Anand Vihar, he has channeled his analytical mindset into a passion  ...\n",
      "\n",
      "============================\n",
      "FILE NAME: contact_links\n",
      "----------------------------\n",
      "# Contact & Professional Links\n",
      "\n",
      "## Primary Contact\n",
      "**Email:** tyagiayush239@gmail.com\n",
      "\n",
      "## Professional Profiles\n",
      "- **LinkedIn:** [linkedin.com/in/ayush-tyagi-0a3694267](https://www.linkedin.com/in/ayush-tyagi-0a3694267)\n",
      "- **GitHub:** [github.com/AyushTyagi239](https://github.com/AyushTyagi239)\n",
      "\n",
      "## Pr ...\n",
      "\n",
      "============================\n",
      "FILE NAME: personal_details\n",
      "----------------------------\n",
      "# Personal Details\n",
      "\n",
      "**Name:** Ayush Tyagi  \n",
      "**Email:** tyagiayush239@gmail.com  \n",
      "**Location:** Delhi NCR, India  \n",
      "**Status:** Computer Science Engineering Student  \n",
      "**Institution:** JIMS, Greater Noida (IP University)  \n",
      "**Graduation:** 2025  \n",
      "\n",
      "## Education Background\n",
      "- **School:** Vivekanand School, ...\n",
      "\n",
      "============================\n",
      "FILE NAME: tagline\n",
      "----------------------------\n",
      "# Personal Tagline\n",
      "\n",
      "**\"Code with passion, design with vision, and celebrate every milestone.\"**\n",
      "\n",
      "## Philosophy Behind the Tagline\n",
      "This tagline represents my approach to technology and life:\n",
      "- **Code with passion:** Bringing enthusiasm and dedication to every line of code\n",
      "- **Design with vision:** Cr ...\n"
     ]
    }
   ],
   "source": [
    "context = {}  # dictionary to store files\n",
    "\n",
    "about_files = glob.glob(\"knowledge-base/about/*\")\n",
    "\n",
    "for file_path in about_files:\n",
    "    # extract filename without extension\n",
    "    filename = os.path.basename(file_path)[:-3]   # removes .md or .txt\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[filename] = doc\n",
    "\n",
    "# ✅ Print what’s inside the context dictionary\n",
    "for key, value in context.items():\n",
    "    print(\"\\n============================\")\n",
    "    print(\"FILE NAME:\", key)\n",
    "    print(\"----------------------------\")\n",
    "    print(value[:300], \"...\")  # print first 300 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86934b0-1b33-4dc7-b76b-e2c1db37b54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bio', 'contact_links', 'personal_details', 'tagline'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d231f9-091e-4c72-b0f8-6af578a74e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CONTEXT LOADED =====\n",
      "\n",
      "FILE NAME: certifications\n",
      "----------------------------\n",
      "# Certifications & Courses\n",
      "\n",
      "## Technical Certifications\n",
      "\n",
      "### 1. Tableau for Data Analysis\n",
      "**Skills Learned:** \n",
      "- Data visualization techniques\n",
      "- Creating interactive dashboards\n",
      "- Connecting to various data sources\n",
      "- Using calculated fields\n",
      "- Storytelling with data\n",
      "\n",
      "### 2. Backend Development (40-Hou...\n",
      "\n",
      "\n",
      "FILE NAME: college\n",
      "----------------------------\n",
      "# College Education\n",
      "\n",
      "**Institution:** JIMS, Greater Noida  \n",
      "**University:** IP University  \n",
      "**Degree:** B.Tech in Computer Science and Engineering  \n",
      "**Duration:** 2021 - 2025 (Expected)  \n",
      "**Current CGPA:** 7.3\n",
      "\n",
      "## Academic Focus\n",
      "- Core computer science fundamentals\n",
      "- Software engineering principles\n",
      "...\n",
      "\n",
      "\n",
      "FILE NAME: school\n",
      "----------------------------\n",
      "# School Education\n",
      "\n",
      "**Institution:** Vivekanand School, Anand Vihar  \n",
      "**Stream:** PCM (Physics, Chemistry, Mathematics)  \n",
      "**Year of Passing:** 2021  \n",
      "**Academic Performance:** 8.2 CGPA\n",
      "\n",
      "## Key Highlights\n",
      "- Completed higher secondary education with Science stream\n",
      "- Developed strong foundation in logi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "educations = glob.glob(\"knowledge-base/education/*\")\n",
    "\n",
    "context = {}\n",
    "\n",
    "for education in educations:  # path to each file\n",
    "    name = os.path.basename(education)[:-3]  # safer than split(os.sep)\n",
    "    with open(education, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name] = doc\n",
    "\n",
    "# ✅ Debug print: see what entered the context dictionary\n",
    "print(\"\\n===== CONTEXT LOADED =====\")\n",
    "for key, value in context.items():\n",
    "    print(f\"\\nFILE NAME: {key}\")\n",
    "    print(\"----------------------------\")\n",
    "    print(value[:300] + \"...\\n\")  # print first 300 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba46a57-d973-4195-8fe3-70fc60687192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['certifications', 'college', 'school'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are Ayush Tyagi’s personal professional assistant AI. \n",
    "Your job is to give accurate, helpful answers about Ayush’s work, projects, skills, \n",
    "education, experience, and professional background.\n",
    "\n",
    "Use only the information provided in the context/knowledge-base. \n",
    "If the answer is not present in the context, clearly say that the information is not available.\n",
    "\n",
    "Do NOT guess, fabricate details, or assume anything beyond the given context.\n",
    "\n",
    "Maintain a friendly, clear, concise, and professional tone.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d40e390b-c110-42d5-8d80-daf3295b9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title.lower() in message.lower():\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context    \n",
    "    #this is ver basic and brittle and breaks for case sensitive andmissing last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d126cfcb-e85c-4dd9-837e-9d2b8436d4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"Who is ayush?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c768d-c47a-4c34-85e9-7b786da96507",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_context(\"Who is Avery and what is carllm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7cef7f-f214-4bac-8217-3f9ab9ba1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if relevant_context:\n",
    "        message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
    "        for relevant in relevant_context:\n",
    "            message += relevant + \"\\n\\n\"\n",
    "    return message\n",
    "    #this is only doing the string look up and not missing the trick "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36399c-440b-4049-9d39-68d208283c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(add_context(\"Who is Alex Lancaster?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history #Ai_inst+history\n",
    "    message = add_context(message) #adding info from knowlegdebase like name product detail\n",
    "    messages.append({\"role\": \"user\", \"content\": message}) #improved user message \n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "    #sends the entire conversation to the AI and asks it to start generating a response piece by piece\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "## Now we will bring this up in Gradio using the Chat interface -\n",
    "\n",
    "A quick and easy way to prototype a chat with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48873d11-2fbd-4329-af27-46c781788561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
