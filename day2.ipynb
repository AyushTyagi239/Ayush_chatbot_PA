{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering agent that is an expert knowledge worker\n",
    "### To be used by employees of Insurellm, an Insurance Tech company\n",
    "### The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy.\n",
    "\n",
    "## TODAY:\n",
    "\n",
    "- Part A: We will divide our documents into CHUNKS\n",
    "- Part B: We will encode our CHUNKS into VECTORS and put in Chroma\n",
    "- Part C: We will visualize our vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769edb3",
   "metadata": {},
   "source": [
    "### PART A: Divide our documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins nvapi-JH\n"
     ]
    }
   ],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"moonshotai/kimi-k2-instruct-0905\"\n",
    "db_name = \"vector_db\"\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('kimi_k2_api_key')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 files in the knowledge base\n",
      "Total characters in knowledge base: 44,314\n"
     ]
    }
   ],
   "source": [
    "# How many characters in all the documents?\n",
    "\n",
    "knowledge_base_path = \"knowledge-base/**/*.md\"\n",
    "files = glob.glob(knowledge_base_path, recursive=True)\n",
    "print(f\"Found {len(files)} files in the knowledge base\")\n",
    "\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        entire_knowledge_base += f.read()\n",
    "        entire_knowledge_base += \"\\n\\n\"\n",
    "\n",
    "print(f\"Total characters in knowledge base: {len(entire_knowledge_base):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 documents\n"
     ]
    }
   ],
   "source": [
    "# Load in everything in the knowledgebase using LangChain's loaders\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68dab1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\about\\\\bio.md', 'doc_type': 'about'}, page_content=\"# Professional Bio\\n\\nAyush Tyagi is a dedicated Computer Science Engineering student at JIMS, Greater Noida (IP University), on track to graduate in 2025. With a strong foundation built during his PCM schooling at Vivekanand School, Anand Vihar, he has channeled his analytical mindset into a passion for technology. \\n\\nAyush thrives on the creative process of front-end development, specializing in building visually stunning, user-friendly, and innovative web applications. He is a proactive learner, constantly seeking new challenges to expand his skill set and create digital experiences that are both functional and beautiful.\\n\\n## What Makes Me Unique\\nMy uniqueness lies in the powerful combination of a creative eye and a logical, problem-solving mindset. I don't just write code; I craft experiences. I have a natural strength for designing interfaces that are not only aesthetically amazing but also intuitive and engaging. This allows me to bridge the gap between technical functionality and user-centric design, ensuring the final product is polished and impactful.\\n\\n## Work Preference\\nI am most energized by projects that push me out of my comfort zone and require me to learn new technologies or innovative solutions. The perfect task is one where I can merge my passion for creating beautiful, modern UIs with the excitement of acquiring and applying new knowledge to solve complex problems.\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25987306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 57 chunks\n",
      "First chunk:\n",
      "\n",
      "page_content='# College Education\n",
      "\n",
      "**Institution:** JIMS, Greater Noida  \n",
      "**University:** IP University  \n",
      "**Degree:** B.Tech in Computer Science and Engineering  \n",
      "**Duration:** 2021 - 2025 (Expected)  \n",
      "**Current CGPA:** 7.3\n",
      "\n",
      "## Academic Focus\n",
      "- Core computer science fundamentals\n",
      "- Software engineering principles\n",
      "- Data structures and algorithms\n",
      "- Web technologies and development\n",
      "- Artificial Intelligence and Machine Learning\n",
      "\n",
      "## Key College Achievements\n",
      "- Consistently maintaining good academic performance\n",
      "- Active participation in technical projects and coding activities\n",
      "- Developing practical skills through personal projects and internships\n",
      "- Building a strong portfolio of web and game development projects\n",
      "\n",
      "## Extracurricular Activities\n",
      "- Technical project development\n",
      "- Self-paced learning through online courses\n",
      "- Participating in coding communities\n",
      "- Building practical applications across multiple domains' metadata={'source': 'knowledge-base\\\\education\\\\college.md', 'doc_type': 'education'}\n"
     ]
    }
   ],
   "source": [
    "# Divide into chunks using the RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Divided into {len(chunks)} chunks\")\n",
    "print(f\"First chunk:\\n\\n{chunks[7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb209db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\experience\\\\intensity_global.md', 'doc_type': 'experience'}, page_content='## Technologies Used\\n- **Programming Languages:** Python\\n- **ML Frameworks:** PyTorch, TensorFlow, Hugging Face Transformers\\n- **AI Tools:** LangChain, LlamaIndex\\n- **Vector Databases:** Pinecone, Chroma, FAISS\\n- **Development Tools:** Git, Docker, Cloud Platforms\\n\\n## Key Achievements\\n- Successfully deployed multiple fine-tuned LLM models for specific use cases\\n- Improved model accuracy through advanced RAG system implementation\\n- Contributed to production-level AI solutions\\n- Enhanced prompt engineering strategies for better output quality\\n\\n## Skills Developed\\n- Advanced LLM fine-tuning techniques\\n- RAG system architecture and implementation\\n- AI pipeline development and deployment\\n- Cross-functional team collaboration\\n- Performance evaluation and optimization')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee2169",
   "metadata": {},
   "source": [
    "### PART B: Make vectors and store in Chroma\n",
    "\n",
    "In Week 3, you set up a Hugging Face account and got an HF_TOKEN\n",
    "\n",
    "At this point, you might want to add it to your `.env` file and run `load_dotenv(override=True)`\n",
    "\n",
    "(This actually shouldn't be required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 57 documents\n"
     ]
    }
   ],
   "source": [
    "# Pick an embedding model\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "#embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "252f17e9-3529-4e81-996c-cfa9f08e75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 413 vectors with 384 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30096a7",
   "metadata": {},
   "source": [
    "### Part C: Visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2052465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_chroma.vectorstores.Chroma object at 0x00000135F157C250>\n",
      "['_Chroma__ensure_collection', '_Chroma__query_collection', '_LANGCHAIN_DEFAULT_COLLECTION_NAME', '__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_asimilarity_search_with_relevance_scores', '_chroma_collection', '_client', '_collection', '_collection_configuration', '_collection_metadata', '_collection_name', '_cosine_relevance_score_fn', '_embedding_function', '_euclidean_relevance_score_fn', '_get_retriever_tags', '_max_inner_product_relevance_score_fn', '_select_relevance_score_fn', '_similarity_search_with_relevance_scores', 'aadd_documents', 'aadd_texts', 'add_documents', 'add_images', 'add_texts', 'adelete', 'afrom_documents', 'afrom_texts', 'aget_by_ids', 'amax_marginal_relevance_search', 'amax_marginal_relevance_search_by_vector', 'as_retriever', 'asearch', 'asimilarity_search', 'asimilarity_search_by_vector', 'asimilarity_search_with_relevance_scores', 'asimilarity_search_with_score', 'delete', 'delete_collection', 'embeddings', 'encode_image', 'fork', 'from_documents', 'from_texts', 'get', 'get_by_ids', 'max_marginal_relevance_search', 'max_marginal_relevance_search_by_vector', 'override_relevance_score_fn', 'reset_collection', 'search', 'similarity_search', 'similarity_search_by_image', 'similarity_search_by_image_with_relevance_score', 'similarity_search_by_vector', 'similarity_search_by_vector_with_relevance_scores', 'similarity_search_with_relevance_scores', 'similarity_search_with_score', 'similarity_search_with_vectors', 'update_document', 'update_documents']\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore)\n",
    "print(dir(vectorstore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48dcb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'name': 'Collection' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      4\u001b[39m client = chromadb.PersistentClient(path=\u001b[33m\"\u001b[39m\u001b[33mdb\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# or your DB path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# name must match what you used earlier\u001b[39;00m\n\u001b[32m      7\u001b[39m result = collection.get(include=[\u001b[33m'\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      8\u001b[39m vectors = np.array(result[\u001b[33m'\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ayush\\AppData\\Local\\anaconda3\\envs\\llms\\Lib\\site-packages\\chromadb\\api\\client.py:208\u001b[39m, in \u001b[36mClient.get_collection\u001b[39m\u001b[34m(self, name, embedding_function, data_loader)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_collection\u001b[39m(\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     data_loader: Optional[DataLoader[Loadable]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    207\u001b[39m ) -> Collection:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     persisted_ef_config = model.configuration_json.get(\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    215\u001b[39m     validate_embedding_function_conflict_on_get(\n\u001b[32m    216\u001b[39m         embedding_function, persisted_ef_config\n\u001b[32m    217\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ayush\\AppData\\Local\\anaconda3\\envs\\llms\\Lib\\site-packages\\chromadb\\api\\rust.py:270\u001b[39m, in \u001b[36mRustBindingsAPI.get_collection\u001b[39m\u001b[34m(self, name, tenant, database)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_collection\u001b[39m(\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m    269\u001b[39m ) -> CollectionModel:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m CollectionModel(\n\u001b[32m    272\u001b[39m         \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    273\u001b[39m         name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m         database=collection.database,\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: argument 'name': 'Collection' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"db\")  # or your DB path\n",
    "collection = client.get_collection(collection)  # name must match what you used earlier\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue','green','red','orange'][['products','employees','contracts','company'].index(t)] for t in doc_types]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8decb0-d9b0-4d51-8402-7a6174d22159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We humans find it easier to visalize things in 2D!\n",
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=10, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65489941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
